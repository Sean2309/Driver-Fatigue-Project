{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Dataset Information\n",
    "\n",
    "\n",
    "Dataset Link : https://www.kaggle.com/datasets/ismailnasri20/driver-drowsiness-dataset-ddd/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to consolidate image paths\n",
    "def consolidate_image_paths(input_path : str, subfolder_name: str) -> list[str]:\n",
    "    return [os.path.join(input_path, subfolder_name, p) for p in os.listdir(os.path.join(input_path, subfolder_name))]\n",
    "\n",
    "# Helper function to map image paths to labels\n",
    "def map_image_paths_to_labels(image_paths: list[str], label: int) -> dict:\n",
    "    return {p: label for p in image_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Images: 41793\n",
      "Difference between Drowsy and Non-Drowsy: 2903\n"
     ]
    }
   ],
   "source": [
    "# Start of Dataset 2 ============================================================================================================\n",
    "base_path_2 = \"./Datasets/Dataset_2/\"\n",
    "\n",
    "# Adds the relative paths of all the images in the dataset\n",
    "drowsy_paths = consolidate_image_paths(base_path_2, \"Drowsy\")\n",
    "non_drowsy_paths = consolidate_image_paths(base_path_2, \"Non Drowsy\")\n",
    "\n",
    "# Combining all the paths\n",
    "# all_paths = drowsy_paths + non_drowsy_paths\n",
    "\n",
    "# Mapping the image paths to their respective labels\n",
    "drowsy_labels = map_image_paths_to_labels(drowsy_paths, 1)\n",
    "non_drowsy_labels = map_image_paths_to_labels(non_drowsy_paths, 0)\n",
    "\n",
    "# Combining all the labels\n",
    "all_labels = {**drowsy_labels, **non_drowsy_labels}\n",
    "\n",
    "print(f\"Total Number of Images: {len(all_labels)}\")\n",
    "print(f\"Difference between Drowsy and Non-Drowsy: {len(drowsy_labels) - len(non_drowsy_labels)}\")\n",
    "\n",
    "# TODO : Add some visuals in seaborn to show the distribution of the labels\n",
    "# End of Dataset 2 ============================================================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights from Dataset 2\n",
    "\n",
    "- There are `2903` drowsy images than non-drowsy images.\n",
    "- The dataset is imbalanced.\n",
    "- To balance the dataset, we can consider several techniques:\n",
    "    - Oversampling\n",
    "    - Undersampling\n",
    "    - Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "### `Steps`:\n",
    "1. Image Resizing\n",
    "2. Data Splitting\n",
    "3. Reshuffling\n",
    "4. Undersampling (Majority Class)\n",
    "5. Data Augmentation (for training data)\n",
    "6. Data Normalization\n",
    "\n",
    "### Preprocessing Steps Methodology\n",
    "1. **Image Resizing**:\n",
    "    - The images should be resized first to ensure all images are of the same dimensions.\n",
    "    - The images are resized to `224x224` pixels.\n",
    "\n",
    "2. **Data Splitting**:\n",
    "    - Dataset should be split before any form of augmentation or sampling to ensure that the model is evaluated on unseen data.\n",
    "    - Augmented data can be spilt into the testing and validation sets otherwise.\n",
    "    - The dataset is split into `70%` training, `15%` validation and `15%` testing sets.\n",
    "\n",
    "3. **Reshuffling**:\n",
    "    - The dataset is reshuffled to ensure that the data is not ordered in any way.\n",
    "    - This helps to prevent the model from learning any patterns in the data that may not be present in real-world scenarios.\n",
    "\n",
    "4. **Undersampling**:\n",
    "    - The majority class is undersampled to the number of images in the minority class.\n",
    "\n",
    "5. **Data Augmentation**:\n",
    "    - Data Augmentation is applied to the training set only to increase the variability of the training data. \n",
    "    - This helps to prevent overfitting and help to contextualise to real-world scenarios. \n",
    "    - Possible augmentations are:\n",
    "        - Rotation\n",
    "        - Horizontal Flip\n",
    "        - Vertical Flip\n",
    "        - Increasing the brightness\n",
    "\n",
    "6. **Data Normalization**:\n",
    "    - The pixel values are normalized to the range `[0, 1]` by dividing by `255`.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Resizing. Default resized dim : 224x224\n",
    "def resize_image(image_path : str, size : tuple[int, int] = (224, 224)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Resizes an image to the specified size and returns the resized image as an ndarray.\n",
    "    Handles potential errors if the image cannot be loaded.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Checking if image exists\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Error reading image from path: {image_path}\")\n",
    "\n",
    "    image = cv2.resize(image, size)\n",
    "    return image\n",
    "\n",
    "# Function to save the resized image\n",
    "def save_resized_image(image: np.ndarray, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the resized image to the specified output path.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "# Data Splitting\n",
    "def split_data(X, y): # will the X and y be a dictionary or a list?\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Shuffle Image Paths\n",
    "def shuffle_paths(paths_dict : list[tuple]) -> list[tuple]:\n",
    "    paths_dict = np.random.shuffle(paths_dict)\n",
    "    return paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing Images |██████████████████████████████████████████████████| 41793/41793|████████▎                                         | ▆▄▂ 6934/41|████████████▊                                     | ▅▇▇ 10657/4|█████████████▉                                    | ▁▃▅ 11556/4|███████████████▍                                  | ▂▄▆ 12818/4|████████████████████████                          | ▆▄▂ 20024/4|█████████████████████████                         | ▂▄▆ 20901/4|██████████████████████████▋                       | ▄▆█ 22218/4|███████████████████████████▋                      | ▇▅▃ 23100/4|███████████████████████████▉                      | ▇▅▃ 23283/4|████████████████████████████▍                     | ▃▅▇ 23705/4|█████████████████████████████                     | ▁▃▅ 24244/4|█████████████████████████████▉                    | ▅▇▇ 24955/4|██████████████████████████████▏                   | ▇▇▅ 25134/4|██████████████████████████████▏                   | ▂▂▄ 25210/4|███████████████████████████████▊                  | ▂▄▆ 26586/4|████████████████████████████████                  | ▃▅▇ 26744/4|████████████████████████████████▎                 | ▆█▆ 26909/4|██████████████████████████████████████▉           | ▆▄▂ 32528/4|███████████████████████████████████████▌          | ▄▆█ 33031/4|███████████████████████████████████████████████▊  | ▆█▆ 39955/4\n"
     ]
    }
   ],
   "source": [
    "# Image Resizing\n",
    "output_folder_path = os.path.join(base_path_2, \"Resized_Images\")\n",
    "\n",
    "# Loop through all the images and resize them\n",
    "with alive_bar(len(all_labels), title=\"Resizing Images\", length=50, force_tty=True) as bar:\n",
    "    for image_path, label in all_labels.items():\n",
    "        try:\n",
    "            # Resize the image\n",
    "            resized_image = resize_image(image_path, (224, 224))\n",
    "\n",
    "            # Create output file path\n",
    "            output_file_name = os.path.basename(image_path)\n",
    "            output_path = os.path.join(output_folder_path, output_file_name)\n",
    "\n",
    "            # Save the resized image\n",
    "            save_resized_image(resized_image, output_path)\n",
    "\n",
    "            # Progress update\n",
    "            bar()\n",
    "            sys.stdout.flush()  # Force flushing the output buffer\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping image {image_path}: {e}\")\n",
    "            sys.stdout.flush()  # Force flushing the output buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
